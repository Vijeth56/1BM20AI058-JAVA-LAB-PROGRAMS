{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr6ACFIW1bXV",
        "outputId": "5fd3f303-2e7f-4173-aed5-fd491afd4fa3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from heapq import nlargest\n",
        "\n",
        "def get_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "def tokenize_and_count_words(text):\n",
        "    # Tokenization\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "    # Remove stopwords and punctuations\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Word count\n",
        "    word_count = Counter(words)\n",
        "    return word_count\n",
        "\n",
        "def perform_text_summarization(text, num_sentences=3):\n",
        "    # Remove extra whitespaces and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
        "\n",
        "    # Calculate sentence scores based on word frequency\n",
        "    word_count = tokenize_and_count_words(text)\n",
        "    sentence_scores = {sentence: sum(word_count[word] for word in re.findall(r'\\b\\w+\\b', sentence.lower()) if word.isalpha()) for sentence in sentences}\n",
        "\n",
        "    # Select top-ranked sentences for summary\n",
        "    summary_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "    summary = ' '.join(summary_sentences)\n",
        "    return summary\n",
        "\n",
        "# URL of the social media web page to scrape\n",
        "url = 'https://www.geeksforgeeks.org/python-program-crawl-web-page-get-frequent-words/'  # Replace with the actual URL\n",
        "\n",
        "# Get text from the web page\n",
        "text = get_text_from_url(url)\n",
        "\n",
        "# Tokenization and word count\n",
        "word_count = tokenize_and_count_words(text)\n",
        "print(\"Word Count:\")\n",
        "wcount = 0\n",
        "for word, count in word_count.items():\n",
        "    wcount+=1\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Text summarization\n",
        "summary = perform_text_summarization(text)\n",
        "print (\"Wordcount\")\n",
        "print(wcount)\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q54zG3x0-rI",
        "outputId": "76e7a48c-ac07-45a4-833e-c5eba426e643"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count:\n",
            "python: 7\n",
            "program: 11\n",
            "crawl: 5\n",
            "web: 15\n",
            "page: 7\n",
            "get: 8\n",
            "frequent: 10\n",
            "word: 23\n",
            "geeksforgeek: 4\n",
            "skip: 1\n",
            "content: 7\n",
            "coursesdata: 1\n",
            "structur: 9\n",
            "algorithmsdsa: 1\n",
            "interview: 14\n",
            "preparationdsa: 1\n",
            "live: 14\n",
            "work: 2\n",
            "professionalsdsa: 1\n",
            "self: 7\n",
            "pace: 6\n",
            "c: 5\n",
            "javadsa: 1\n",
            "pythondsa: 1\n",
            "javascriptdsa: 1\n",
            "cfor: 1\n",
            "professionalsdata: 1\n",
            "algorithm: 6\n",
            "class: 48\n",
            "system: 2\n",
            "design: 7\n",
            "devop: 2\n",
            "data: 24\n",
            "javascriptexplor: 1\n",
            "coursesfor: 1\n",
            "studentsinterview: 1\n",
            "prepar: 4\n",
            "coursedata: 3\n",
            "scienc: 18\n",
            "gate: 6\n",
            "cs: 16\n",
            "javascriptdata: 1\n",
            "java: 2\n",
            "pythonexplor: 1\n",
            "coursesprogram: 1\n",
            "languagesc: 1\n",
            "beginn: 3\n",
            "advancedjava: 1\n",
            "advancedc: 1\n",
            "advancedweb: 1\n",
            "developmentful: 1\n",
            "stack: 2\n",
            "develop: 7\n",
            "react: 3\n",
            "node: 2\n",
            "js: 2\n",
            "backend: 4\n",
            "android: 2\n",
            "app: 3\n",
            "kotlin: 2\n",
            "django: 2\n",
            "machin: 3\n",
            "learn: 11\n",
            "sciencecomplet: 1\n",
            "master: 1\n",
            "analyticsnew: 1\n",
            "coursespython: 1\n",
            "engin: 2\n",
            "plan: 1\n",
            "productionschool: 1\n",
            "coursescbs: 1\n",
            "comput: 2\n",
            "scienceschool: 1\n",
            "guideal: 1\n",
            "coursestutorialsdsadata: 1\n",
            "structuresarrayslink: 3\n",
            "liststackqueuebinari: 3\n",
            "treebinari: 3\n",
            "search: 3\n",
            "treeheaphashinggraphadvanc: 1\n",
            "structurematrixstringsal: 1\n",
            "structuresalgorithmsanalysi: 3\n",
            "algorithmsdesign: 1\n",
            "analysi: 4\n",
            "algorithmsasymptot: 1\n",
            "analysisworst: 1\n",
            "averag: 1\n",
            "best: 3\n",
            "casesasymptot: 1\n",
            "notationslittl: 1\n",
            "littl: 1\n",
            "omega: 1\n",
            "notationslow: 1\n",
            "upper: 1\n",
            "bound: 1\n",
            "theoryanalysi: 1\n",
            "loopssolv: 1\n",
            "recurrencesamort: 1\n",
            "analysiswhat: 1\n",
            "space: 2\n",
            "complex: 2\n",
            "mean: 1\n",
            "pseudo: 1\n",
            "polynomi: 1\n",
            "algorithmspolynomi: 1\n",
            "time: 2\n",
            "approxim: 1\n",
            "schemea: 1\n",
            "questionsearch: 1\n",
            "algorithmssort: 3\n",
            "algorithmsgraph: 1\n",
            "algorithmspattern: 3\n",
            "searchinggeometr: 3\n",
            "algorithmsmathematicalbitwis: 1\n",
            "algorithmsrandom: 3\n",
            "algorithmsgreedi: 3\n",
            "algorithmsdynam: 3\n",
            "programmingdivid: 3\n",
            "conquerbacktrackingbranch: 3\n",
            "boundal: 3\n",
            "algorithmssystem: 1\n",
            "designsystem: 1\n",
            "tutorialsoftwar: 1\n",
            "patternsinterview: 1\n",
            "cornercompani: 2\n",
            "preparationtop: 1\n",
            "topicspractic: 1\n",
            "compani: 3\n",
            "questionsinterview: 2\n",
            "experiencesexperienc: 1\n",
            "interviewsinternship: 1\n",
            "interviewscompetit: 1\n",
            "programmingmultipl: 1\n",
            "choic: 1\n",
            "quizzesaptitud: 1\n",
            "placementslanguagescc: 1\n",
            "javapythonjavascriptphpc: 1\n",
            "sqlscalaperlgo: 1\n",
            "languagekotlinweb: 1\n",
            "developmenthtmlcssjavascriptphpcss: 1\n",
            "frameworksbootstraptailwind: 1\n",
            "cssfoundat: 1\n",
            "cssmateri: 1\n",
            "cssbulmapur: 1\n",
            "cssprimer: 1\n",
            "cssblaze: 1\n",
            "uisemant: 1\n",
            "uijavascript: 1\n",
            "frameworksangularjsangular: 1\n",
            "primengangular: 1\n",
            "ngx: 1\n",
            "bootstrapnodejsexpress: 1\n",
            "jsjavascript: 1\n",
            "librariesjqueryjqueri: 1\n",
            "mobilejqueri: 1\n",
            "uijqueri: 1\n",
            "easyuijqwidgetsreactjsreact: 1\n",
            "bootstrapreact: 1\n",
            "rebassreact: 1\n",
            "desktopreact: 1\n",
            "suitereactj: 1\n",
            "evergreenreactj: 1\n",
            "reactstrap: 1\n",
            "jslodashtensorflow: 1\n",
            "jsmoment: 1\n",
            "jscollect: 1\n",
            "jswordpressjsonschool: 1\n",
            "learningenglish: 1\n",
            "grammarschool: 1\n",
            "programmingmathematicsnumb: 1\n",
            "systemalgebratrigonometrystatisticsprobabilitygeometrymensurationcalculuscbs: 1\n",
            "syllabu: 3\n",
            "syllabusclass: 7\n",
            "syllabusmath: 1\n",
            "note: 19\n",
            "notesclass: 19\n",
            "notesmath: 1\n",
            "formula: 1\n",
            "formulasclass: 3\n",
            "formulasncert: 1\n",
            "solutionsclass: 2\n",
            "math: 10\n",
            "solutionclass: 8\n",
            "solutionrd: 1\n",
            "sharma: 1\n",
            "solutionsci: 1\n",
            "notesphys: 1\n",
            "noteschemistri: 1\n",
            "notesbiolog: 1\n",
            "ss: 4\n",
            "syllabussoci: 1\n",
            "notesss: 1\n",
            "notescbs: 9\n",
            "histori: 2\n",
            "geographi: 1\n",
            "geo: 1\n",
            "civic: 2\n",
            "studi: 2\n",
            "microeconom: 1\n",
            "statist: 1\n",
            "econom: 2\n",
            "busi: 1\n",
            "account: 1\n",
            "macroeconom: 1\n",
            "cbse: 1\n",
            "previou: 3\n",
            "year: 11\n",
            "papersmathsphysicshistorygeorgraphypolit: 1\n",
            "scienceeconomicsml: 1\n",
            "sciencemachin: 1\n",
            "learningdata: 1\n",
            "sciencedevopsgitawsdockerkubernetesmicrosoft: 1\n",
            "azur: 3\n",
            "tutorialgoogl: 1\n",
            "cloud: 1\n",
            "platformc: 1\n",
            "subjectsmathematicsoper: 1\n",
            "systemdbmscomput: 1\n",
            "networkscomput: 1\n",
            "organ: 3\n",
            "architecturetheori: 1\n",
            "computationcompil: 1\n",
            "designdigit: 3\n",
            "logicsoftwar: 1\n",
            "engineeringgateg: 1\n",
            "courseg: 1\n",
            "noteslast: 1\n",
            "minut: 3\n",
            "notesg: 3\n",
            "solv: 3\n",
            "papersg: 1\n",
            "origin: 2\n",
            "paper: 6\n",
            "offici: 2\n",
            "keysgat: 1\n",
            "syllabusimport: 1\n",
            "topic: 7\n",
            "csgate: 5\n",
            "import: 5\n",
            "datesoth: 1\n",
            "examsisroisro: 1\n",
            "keysisro: 1\n",
            "papersisro: 1\n",
            "scientist: 1\n",
            "examugc: 1\n",
            "netugc: 1\n",
            "net: 3\n",
            "iiugc: 1\n",
            "iiiugc: 1\n",
            "papersgfg: 1\n",
            "sheetsweb: 1\n",
            "dev: 1\n",
            "cheat: 7\n",
            "sheetshtml: 1\n",
            "sheetcss: 1\n",
            "sheetbootstrap: 1\n",
            "sheetj: 1\n",
            "sheetjqueri: 1\n",
            "sheetangular: 1\n",
            "sheetcompani: 2\n",
            "wise: 10\n",
            "sde: 7\n",
            "sheetsfacebook: 1\n",
            "sheetamazon: 1\n",
            "sheetappl: 1\n",
            "sheetnetflix: 1\n",
            "sheetgoogl: 1\n",
            "sheetwipro: 1\n",
            "code: 14\n",
            "sheetinfosi: 1\n",
            "sheettc: 1\n",
            "sheetcogniz: 1\n",
            "sheethcl: 1\n",
            "sheetdsa: 1\n",
            "sheetssd: 1\n",
            "sheetfaang: 1\n",
            "sheetlov: 1\n",
            "babbar: 1\n",
            "sheetmass: 1\n",
            "recruit: 1\n",
            "sheetproduct: 1\n",
            "base: 1\n",
            "sheetarray: 1\n",
            "sheetstr: 1\n",
            "sheettre: 1\n",
            "sheetgraph: 1\n",
            "sheetdp: 1\n",
            "sheetupscgeographi: 1\n",
            "noteshistori: 2\n",
            "notessci: 2\n",
            "tech: 1\n",
            "noteseth: 1\n",
            "notespol: 1\n",
            "noteseconom: 2\n",
            "notesupsc: 1\n",
            "papersstudentcampu: 1\n",
            "ambassador: 2\n",
            "programschool: 1\n",
            "programprojectgeek: 1\n",
            "monthcampu: 1\n",
            "geek: 1\n",
            "monthplac: 1\n",
            "coursecompetit: 1\n",
            "programmingtestimonialsstud: 1\n",
            "chaptergeek: 1\n",
            "topinternshipcareersssc: 1\n",
            "cglssc: 1\n",
            "cgl: 3\n",
            "syllabusgener: 3\n",
            "studiesenglishreasoningsubjectwis: 1\n",
            "practic: 6\n",
            "papersprevi: 1\n",
            "papersbank: 1\n",
            "examssbi: 1\n",
            "clerksbi: 1\n",
            "clerk: 5\n",
            "awarenessenglishquantit: 2\n",
            "aptitudereason: 2\n",
            "abilitysbi: 1\n",
            "paperssbi: 2\n",
            "posbi: 1\n",
            "po: 5\n",
            "abilityprevi: 1\n",
            "papersibp: 1\n",
            "poibp: 1\n",
            "syllabusenglish: 2\n",
            "notesreason: 1\n",
            "notesprevi: 2\n",
            "papersmock: 1\n",
            "question: 5\n",
            "papersgener: 1\n",
            "awarenessibp: 1\n",
            "clerkibp: 1\n",
            "papersjobscorpor: 1\n",
            "hire: 2\n",
            "solutionsappli: 1\n",
            "jobathonappli: 1\n",
            "jobpracticeal: 1\n",
            "dsa: 3\n",
            "problemsproblem: 1\n",
            "daygfg: 1\n",
            "sheetcur: 1\n",
            "liststop: 1\n",
            "array: 2\n",
            "problemstop: 9\n",
            "string: 4\n",
            "tree: 2\n",
            "graph: 2\n",
            "dp: 2\n",
            "problemscontestsgfg: 1\n",
            "weekli: 1\n",
            "contestjob: 1\n",
            "thon: 1\n",
            "challengebiwizard: 1\n",
            "school: 1\n",
            "contestal: 1\n",
            "contest: 1\n",
            "event: 1\n",
            "homesav: 1\n",
            "videoscoursesgblogpuzzleswhat: 1\n",
            "new: 1\n",
            "chang: 2\n",
            "languag: 3\n",
            "typescontrol: 1\n",
            "flowfunctionsliststringsettupledictionaryoopsexcept: 1\n",
            "handlingpython: 1\n",
            "programspython: 1\n",
            "projectspython: 3\n",
            "questionspython: 1\n",
            "mcqnumpypandaspython: 1\n",
            "databasedata: 1\n",
            "pythonmachin: 1\n",
            "pythondjangoflaskr: 1\n",
            "relat: 1\n",
            "articl: 12\n",
            "appgeeksforgeek: 1\n",
            "appopen: 1\n",
            "appbrowsercontinuerel: 1\n",
            "articleswrit: 1\n",
            "experiencewrit: 2\n",
            "admiss: 2\n",
            "experienceinterview: 2\n",
            "preparationinterview: 2\n",
            "softwar: 2\n",
            "developersmust: 2\n",
            "wisemust: 2\n",
            "wisecompani: 2\n",
            "problemscompani: 2\n",
            "preparationcompetit: 2\n",
            "programmingsoftwar: 2\n",
            "patternscompani: 2\n",
            "experienceexperienc: 2\n",
            "experiencesinternship: 2\n",
            "experiencespractic: 2\n",
            "geeksforgeeksproblem: 2\n",
            "daytop: 2\n",
            "practicedifficulti: 2\n",
            "level: 12\n",
            "schooldifficulti: 2\n",
            "basicdifficulti: 2\n",
            "easydifficulti: 2\n",
            "mediumdifficulti: 2\n",
            "hardleaderboard: 2\n",
            "explor: 2\n",
            "treeheaphashinggraphadv: 2\n",
            "structuresmatrixstringal: 2\n",
            "algorithmssearch: 2\n",
            "algorithmsmathemat: 2\n",
            "algorithmsprogram: 2\n",
            "languagescc: 2\n",
            "javapythonc: 2\n",
            "go: 2\n",
            "langsqlphpscalaperlkotlinweb: 2\n",
            "jslodash: 2\n",
            "jsjqwidgetjqueri: 2\n",
            "uiwordpresstailwind: 2\n",
            "cssjsonjqueri: 2\n",
            "mobilecollect: 2\n",
            "jspure: 2\n",
            "cssbulmafoundationmateri: 2\n",
            "csssemant: 2\n",
            "uitypescriptsvgexpress: 2\n",
            "jsant: 2\n",
            "designreact: 2\n",
            "designtensorflow: 2\n",
            "jscomput: 2\n",
            "subjectsoper: 2\n",
            "systemsdbmscomput: 2\n",
            "networkcomput: 2\n",
            "architecturetoccompil: 2\n",
            "elec: 2\n",
            "logic: 3\n",
            "designsoftwar: 2\n",
            "engineeringengin: 2\n",
            "mathematicsdata: 2\n",
            "mlcomplet: 2\n",
            "tutorialmachin: 4\n",
            "tutorialdeep: 3\n",
            "tutorialnlp: 3\n",
            "projectsdata: 2\n",
            "tutorialtutori: 2\n",
            "librarypython: 2\n",
            "tutorialdjango: 2\n",
            "tutorialpanda: 2\n",
            "tutorialkivi: 2\n",
            "tutorialtkint: 2\n",
            "tutorialopencv: 2\n",
            "tutorialselenium: 2\n",
            "tutorialg: 2\n",
            "cornerprevi: 2\n",
            "paperslast: 2\n",
            "lmn: 2\n",
            "courseprevi: 2\n",
            "examsdevopsgit: 2\n",
            "tutorialaw: 2\n",
            "tutorialdock: 2\n",
            "tutorialkubernet: 2\n",
            "tutorialmicrosoft: 2\n",
            "tutorialquiz: 2\n",
            "sectionc: 2\n",
            "quizc: 2\n",
            "quizjava: 2\n",
            "quizpython: 2\n",
            "quizhtml: 2\n",
            "quizcss: 2\n",
            "quizjavascript: 2\n",
            "quizdata: 2\n",
            "quizalgorithm: 2\n",
            "quiztop: 2\n",
            "mcqsschool: 2\n",
            "contentcbs: 2\n",
            "boardcbs: 2\n",
            "notesschool: 2\n",
            "programmingenglish: 2\n",
            "grammarwrit: 1\n",
            "grammarpython: 1\n",
            "wordsimprov: 1\n",
            "save: 3\n",
            "like: 3\n",
            "publish: 1\n",
            "articlesreaddiscusscoursespracticevideoimprov: 1\n",
            "task: 1\n",
            "count: 6\n",
            "extract: 3\n",
            "dynam: 1\n",
            "sourc: 2\n",
            "first: 1\n",
            "creat: 2\n",
            "crawler: 3\n",
            "scraper: 1\n",
            "help: 1\n",
            "request: 5\n",
            "modul: 3\n",
            "beauti: 1\n",
            "soup: 3\n",
            "store: 3\n",
            "list: 2\n",
            "might: 1\n",
            "undesir: 1\n",
            "symbol: 6\n",
            "special: 1\n",
            "blank: 1\n",
            "filter: 1\n",
            "order: 1\n",
            "eas: 1\n",
            "desir: 1\n",
            "result: 1\n",
            "also: 1\n",
            "say: 1\n",
            "librari: 1\n",
            "function: 5\n",
            "use: 7\n",
            "allow: 1\n",
            "send: 1\n",
            "http: 2\n",
            "mani: 1\n",
            "pars: 1\n",
            "html: 3\n",
            "xml: 2\n",
            "file: 1\n",
            "oper: 4\n",
            "export: 1\n",
            "set: 2\n",
            "effici: 1\n",
            "correspond: 2\n",
            "intrins: 1\n",
            "collect: 2\n",
            "implement: 2\n",
            "high: 1\n",
            "perform: 1\n",
            "contain: 2\n",
            "datatyp: 1\n",
            "idea: 1\n",
            "discuss: 2\n",
            "frequenc: 1\n",
            "counter: 3\n",
            "scrape: 1\n",
            "pageimport: 1\n",
            "requestsfrom: 1\n",
            "beautifulsoupimport: 1\n",
            "operatorfrom: 1\n",
            "defin: 1\n",
            "corespid: 1\n",
            "fetch: 2\n",
            "inform: 1\n",
            "froma: 1\n",
            "given: 2\n",
            "websit: 4\n",
            "push: 1\n",
            "toth: 1\n",
            "second: 2\n",
            "def: 3\n",
            "start: 3\n",
            "url: 5\n",
            "empti: 1\n",
            "wordlist: 5\n",
            "text: 3\n",
            "beautifulsoup: 2\n",
            "object: 1\n",
            "ping: 1\n",
            "parser: 1\n",
            "div: 2\n",
            "tag: 3\n",
            "entri: 2\n",
            "findal: 1\n",
            "split: 2\n",
            "break: 1\n",
            "sentenc: 1\n",
            "convert: 1\n",
            "lowercas: 1\n",
            "lower: 1\n",
            "append: 2\n",
            "remov: 1\n",
            "unwant: 1\n",
            "rang: 1\n",
            "len: 2\n",
            "replac: 1\n",
            "dictionari: 1\n",
            "occur: 2\n",
            "els: 1\n",
            "itemgett: 2\n",
            "take: 1\n",
            "one: 1\n",
            "paramet: 1\n",
            "either: 1\n",
            "denot: 2\n",
            "key: 4\n",
            "valu: 5\n",
            "sort: 1\n",
            "item: 1\n",
            "print: 3\n",
            "return: 1\n",
            "element: 3\n",
            "top: 2\n",
            "driver: 1\n",
            "codeif: 1\n",
            "www: 1\n",
            "org: 1\n",
            "choos: 1\n",
            "output: 1\n",
            "person: 1\n",
            "updat: 1\n",
            "nov: 1\n",
            "pleas: 1\n",
            "login: 1\n",
            "comment: 1\n",
            "similar: 1\n",
            "find: 3\n",
            "k: 1\n",
            "differ: 1\n",
            "browser: 2\n",
            "size: 1\n",
            "screen: 1\n",
            "current: 1\n",
            "window: 1\n",
            "jqueri: 1\n",
            "php: 2\n",
            "display: 1\n",
            "panda: 1\n",
            "seri: 1\n",
            "numpi: 1\n",
            "comparison: 1\n",
            "flask: 1\n",
            "onsen: 1\n",
            "materi: 1\n",
            "nuxtj: 1\n",
            "likepreviousf: 1\n",
            "pythonnext: 1\n",
            "reactj: 1\n",
            "listsarticl: 1\n",
            "contribut: 1\n",
            "difficultycurr: 1\n",
            "difficulti: 1\n",
            "mediumeasi: 1\n",
            "normal: 1\n",
            "medium: 1\n",
            "hard: 1\n",
            "expertimprov: 1\n",
            "utilitypythontechn: 1\n",
            "scripterweb: 1\n",
            "technologiespractic: 1\n",
            "pythonreport: 1\n",
            "issu: 1\n",
            "cours: 1\n",
            "interest: 3\n",
            "geeksful: 1\n",
            "geekscomplet: 1\n",
            "geeksdata: 1\n",
            "pacedexploreimprov: 1\n",
            "skill: 1\n",
            "practicetri: 1\n",
            "floor: 1\n",
            "sovereign: 1\n",
            "corpor: 1\n",
            "tower: 1\n",
            "sector: 1\n",
            "noida: 1\n",
            "uttar: 1\n",
            "pradesh: 1\n",
            "feedback: 2\n",
            "orgcompanyabout: 1\n",
            "uscareersin: 1\n",
            "mediacontact: 1\n",
            "usterm: 1\n",
            "conditionsprivaci: 1\n",
            "policycopyright: 1\n",
            "policythird: 1\n",
            "parti: 1\n",
            "copyright: 1\n",
            "noticesadvertis: 1\n",
            "usexplorejob: 1\n",
            "fair: 1\n",
            "studentspotd: 1\n",
            "revampedpython: 1\n",
            "liveandroid: 1\n",
            "developmentdevop: 1\n",
            "livedsa: 1\n",
            "javascriptlanguagespythonjavac: 1\n",
            "golangsqlr: 1\n",
            "languageandroid: 1\n",
            "tutorialdata: 1\n",
            "structuresarraystringlink: 1\n",
            "liststackqueuetreegraphalgorithmssortingsearchinggreedydynam: 1\n",
            "programmingpattern: 1\n",
            "searchingrecursionbacktrackingweb: 1\n",
            "developmenthtmlcssjavascriptbootstrapreactjsangularjsnodejscomput: 1\n",
            "scienceg: 1\n",
            "notesoper: 1\n",
            "systemscomput: 1\n",
            "networkdatabas: 1\n",
            "manag: 1\n",
            "systemsoftwar: 1\n",
            "engineeringdigit: 1\n",
            "designengin: 1\n",
            "mathspythonpython: 1\n",
            "examplesdjango: 1\n",
            "tutorialpython: 2\n",
            "tkinteropencv: 1\n",
            "questiondata: 1\n",
            "mldata: 1\n",
            "pythondata: 1\n",
            "beginnermachin: 1\n",
            "tutorialmath: 1\n",
            "learningpanda: 1\n",
            "tutorialnumpi: 1\n",
            "tutorialdevopsgitawsdockerkubernetesazuregcpcompetit: 1\n",
            "programmingtop: 1\n",
            "cptop: 1\n",
            "cpsystem: 1\n",
            "designwhat: 1\n",
            "designmonolith: 1\n",
            "distribut: 1\n",
            "sdscalabl: 1\n",
            "sddatabas: 1\n",
            "sdhigh: 1\n",
            "hldlow: 1\n",
            "lldtop: 1\n",
            "sd: 1\n",
            "preparationprepar: 1\n",
            "sdecompani: 1\n",
            "cornerexperienc: 1\n",
            "interviewinternship: 1\n",
            "interviewcompetit: 1\n",
            "programmingaptitudegfg: 1\n",
            "schoolcbs: 1\n",
            "grammarcommerceaccountancybusi: 1\n",
            "studiesmicroeconomicsmacroeconomicsstatist: 1\n",
            "economicsindian: 1\n",
            "developmentupscpol: 1\n",
            "notesgeographi: 1\n",
            "technolog: 1\n",
            "notesimport: 1\n",
            "ethicsupsc: 1\n",
            "papersssc: 1\n",
            "bankingssc: 1\n",
            "syllabussbi: 2\n",
            "syllabusibp: 2\n",
            "syllabusaptitud: 1\n",
            "questionsssc: 1\n",
            "paperswrit: 1\n",
            "earnwrit: 1\n",
            "articleimprov: 1\n",
            "articlepick: 1\n",
            "writewrit: 1\n",
            "experienceinternshipsvideo: 1\n",
            "internship: 1\n",
            "right: 2\n",
            "reservedw: 1\n",
            "cooki: 2\n",
            "ensur: 1\n",
            "brows: 1\n",
            "experi: 1\n",
            "site: 1\n",
            "acknowledg: 1\n",
            "read: 1\n",
            "understood: 1\n",
            "polici: 2\n",
            "privaci: 1\n",
            "got: 1\n",
            "improvementthi: 1\n",
            "improv: 2\n",
            "anoth: 1\n",
            "user: 1\n",
            "suggest: 2\n",
            "tab: 1\n",
            "notifi: 1\n",
            "via: 1\n",
            "email: 1\n",
            "avail: 1\n",
            "thank: 1\n",
            "valuabl: 1\n",
            "changessuggest: 2\n",
            "charlimit: 1\n",
            "Wordcount\n",
            "773\n",
            "\n",
            "Summary:\n",
            "Python program to crawl a web page and get most frequent words - GeeksforGeeks Skip to content CoursesData Structures and AlgorithmsDSA for Interview PreparationDSA Live for Working ProfessionalsDSA Self-paced in C++/JavaDSA Self-paced in PythonDSA Self-paced in JavascriptDSA Self-paced in CFor Working ProfessionalsData Structure & Algorithm Classes (Live)System Design (Live)DevOps(Live)Data Structures & Algorithms in JavaScriptExplore More Live CoursesFor StudentsInterview Preparation CourseData Science (Live)GATE CS & IT 2024Data Structures & Algorithms in JavaScriptData Structure & Algorithm-Self Paced(C++/JAVA)Data Structures & Algorithms in PythonExplore More Self-Paced CoursesProgramming LanguagesC++ Programming - Beginner to AdvancedJava Programming - Beginner to AdvancedC Programming - Beginner to AdvancedWeb DevelopmentFull Stack Development with React & Node JS(Live)Java Backend Development(Live)Android App Development with Kotlin(Live)Python Backend Development with Django(Live)Machine Learning and Data ScienceComplete Data Science Program(Live)Mastering Data AnalyticsNew CoursesPython Backend Development with Django(Live)Android App Development with Kotlin(Live)DevOps Engineering - Planning to ProductionSchool CoursesCBSE Class 12 Computer ScienceSchool GuideAll CoursesTutorialsDSAData StructuresArraysLinked ListStackQueueBinary TreeBinary Search TreeHeapHashingGraphAdvanced Data StructureMatrixStringsAll Data StructuresAlgorithmsAnalysis of AlgorithmsDesign and Analysis of AlgorithmsAsymptotic AnalysisWorst, Average and Best CasesAsymptotic NotationsLittle o and little omega notationsLower and Upper Bound TheoryAnalysis of LoopsSolving RecurrencesAmortized AnalysisWhat does 'Space Complexity' mean ?Pseudo-polynomial AlgorithmsPolynomial Time Approximation SchemeA Time Complexity QuestionSearching AlgorithmsSorting AlgorithmsGraph AlgorithmsPattern SearchingGeometric AlgorithmsMathematicalBitwise AlgorithmsRandomized AlgorithmsGreedy AlgorithmsDynamic ProgrammingDivide and ConquerBacktrackingBranch and BoundAll AlgorithmsSystem DesignSystem Design TutorialSoftware Design PatternsInterview CornerCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsLanguagesCC++JavaPythonJavaScriptPHPC#SQLScalaPerlGo LanguageKotlinWeb DevelopmentHTMLCSSJavaScriptPHPCSS FrameworksBootstrapTailwind CSSFoundation CSSMaterialize CSSBulmaPure CSSPrimer CSSBlaze UISemantic UIJavaScript FrameworksAngularJSAngular PrimeNGAngular ngx BootstrapNodeJSExpress.jsJavaScript LibrariesjQueryjQuery MobilejQuery UIjQuery EasyUIjQWidgetsReactJSReact BootstrapReact RebassReact DesktopReact SuiteReactJS EvergreenReactJS ReactstrapAnt DesignBlueprintJSp5.jsLodashTensorFlow.jsMoment.jsCollect.jsWordPressJSONSchool LearningEnglish GrammarSchool ProgrammingMathematicsNumber SystemAlgebraTrigonometryStatisticsProbabilityGeometryMensurationCalculusCBSE Syllabus Class 8 SyllabusClass 9 SyllabusClass 10 SyllabusClass 11 SyllabusClass 12 SyllabusMaths Notes (Class 8-12)Class 8 NotesClass 9 NotesClass 10 NotesClass 11 NotesClass 12 NotesMaths Formulas (Class 8 -11)Class 8 FormulasClass 9 FormulasClass 10 FormulasClass 11 FormulasNCERT SolutionsClass 8 Maths SolutionClass 9 Maths SolutionClass 10 Maths SolutionClass 11 Maths SolutionClass 12 Maths SolutionRD Sharma SolutionsClass 8 Maths SolutionClass 9 Maths SolutionClass 10 Maths SolutionClass 11 Maths SolutionClass 12 Maths SolutionScience NotesClass 8 NotesClass 9 NotesClass 10 NotesPhysics Notes (Class 8-12)Class 8 NotesClass 9 NotesClass 10 NotesClass 11 NotesClass 12 NotesChemistry Notes (Class 8-12)Class 8 NotesClass 9 NotesClass 10 NotesClass 11 NotesClass 12 NotesBiology NotesClass 8Class 9Class 10Class 11Social Science Syllabus Class 7 SS SyllabusClass 8 SS SyllabusClass 9 SS SyllabusClass 10 SS SyllabusSocial Science NotesSS Notes (Class 7-12)Class 7 NotesClass 8 NotesClass 9 NotesClass 10 NotesCBSE History Notes (Class 7-10)History Class 7History Class 8History Class 9CBSE Geography Notes (Class 7-10)Geo. Class 9CBSE Civics Notes (Class 7-10)Civics Class 7Civics Class 8CommerceBusiness Studies (Class 11th)Microeconomics (Class 11th)Statistics for Economics (Class 11th)Business Studies (Class 12th)Accountancy (Class 12th)Macroeconomics (Class 12th)CBSE Previous Year PapersMathsPhysicsHistoryGeorgraphyPolitical ScienceEconomicsML & Data ScienceMachine LearningData ScienceDevOpsGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformCS SubjectsMathematicsOperating SystemDBMSComputer NetworksComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringGATEGATE 2024 Live CourseGATE Computer Science NotesLast Minute NotesGATE CS Solved PapersGATE CS Original Papers and Official KeysGATE CS 2023 SyllabusImportant Topics for GATE CSGATE 2023 Important DatesOther CS ExamsISROISRO CS Original Papers and Official KeysISRO CS Solved PapersISRO CS Syllabus for Scientist/Engineer ExamUGC NETUGC NET CS Notes Paper IIUGC NET CS Notes Paper IIIUGC NET CS Solved PapersGFG SheetsWeb Dev Cheat SheetsHTML Cheat SheetCSS Cheat SheetBootstrap Cheat SheetJS Cheat SheetjQuery Cheat SheetAngular Cheat SheetCompany-Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetWipro Coding SheetInfosys Coding SheetTCS Coding SheetCognizant Coding SheetHCL Coding SheetDSA SheetsSDE SheetFAANG Coding SheetLove Babbar SheetMass Recruiter SheetProduct-Based Coding SheetCompany-Wise Preparation SheetArray SheetString SheetTree SheetGraph SheetDP SheetUPSCGeography NotesHistory NotesScience & Tech. collections : Implements high-performance container datatypes.Below is an implementation of the idea discussed above : Python3# Python3 program for a word frequency# counter after crawling/scraping a web-pageimport requestsfrom bs4 import BeautifulSoupimport operatorfrom collections import Counter '''Function defining the web-crawler/corespider, which will fetch information froma given website, and push the contents tothe second function clean_wordlist()''' def start(url): # empty list to store the contents of # the website fetched from our web-crawler wordlist = [] source_code = requests.get(url).text # BeautifulSoup object which will # ping the requested url for data soup = BeautifulSoup(source_code, 'html.parser') # Text in given web-page is stored under # the <div> tags with class <entry-content> for each_text in soup.findAll('div', {'class': 'entry-content'}): content = each_text.text # use split() to break the sentence into # words and convert them into lowercase words = content.lower().split() for each_word in words: wordlist.append(each_word) clean_wordlist(wordlist) # Function removes any unwanted symbols def clean_wordlist(wordlist): clean_list = [] for word in wordlist: symbols = \"!@#$%^&*()_-+={[}]|\\;:\\\"<>?/., \" for i in range(len(symbols)): word = word.replace(symbols[i], '') if len(word) > 0: clean_list.append(word) create_dictionary(clean_list) # Creates a dictionary containing each word's# count and top_20 occurring words def create_dictionary(clean_list): word_count = {} for word in clean_list: if word in word_count: word_count[word] += 1 else: word_count[word] = 1 ''' To get the count of each word in the crawled page --> # operator.itemgetter() takes one # parameter either 1(denotes keys) # or 0 (denotes corresponding values) for key, value in sorted(word_count.items(), key = operator.itemgetter(1)): print (\"% s : % s \" % (key, value)) <-- ''' c = Counter(word_count) # returns the most occurring elements top = c.most_common(10) print(top) # Driver codeif __name__ == '__main__': url = \"https://www.geeksforgeeks.org/programming-language-choose/\" # starts crawling and prints output start(url)[('to', 10), ('in', 7), ('is', 6), ('language', 6), ('the', 5), ('programming', 5), ('a', 5), ('c', 5), ('you', 5), ('of', 4)]My Personal Notes arrow_drop_upSaveLast Updated : 18 Nov, 2021Like Article Save Article Please Login to comment...Similar Reads1.\n"
          ]
        }
      ]
    }
  ]
}